{"cells":[{"source":"# Particl Case Study: Web Scraping Tool\n\nby Boston McClary\n\n## Introduction\n\nIn this case study, I developed a web scraping tool in Python to scrape an ecommerce product page. The product page we will be scraping is [Gymshark Crest Sweatshirt](https://us.shop.gymshark.com/products/gymshark-crest-sweatshirt-persimmon-red-ss23).\n\n## Objective\n\nThe objective of this case study is to develop a Python script that can extract relevant information from the product page, such as the product name, price, description, and available sizes.\n\n## Tools and Libraries\n\nTo accomplish this task, I used the following tools and libraries:\n\n- Python\n- Beautiful Soup\n- Requests\n- ChatGPT 3.5 Turbo\n\n## Steps\n\n1. Inspect the product page for each element needed (name, description, price, etc.)\n2. Put those elements into ChatGPT 3.5 asking it to structure the code properly for web scraping\n3. Send a GET request to the product page URL\n4. Parse the HTML content using Beautiful Soup\n5. Extract the relevant information from the parsed HTML\n6. Store the extracted information in a structured format of either JSON or CSV\n\n## Additional Notes\n\nI did end up finding the inventory quantity when digging into the website, but it looks like it's stored in a JavaScript package and therefore the BeautifulSoup code snippet below would not be able to scrape this data. I used ChatGPT to write a new code snippet just to extract this data and it's listed below.\n","metadata":{},"cell_type":"markdown","id":"ffcc405a-fb25-4044-b747-82ae60e3f879"},{"source":"## BeautifulSoup Script","metadata":{},"cell_type":"markdown","id":"8828e3d6-1cf6-457c-a6d9-fbab12d2d30d"},{"source":"import requests\nfrom bs4 import BeautifulSoup\nimport json\nimport csv\n\nURL = \"https://us.shop.gymshark.com/products/gymshark-crest-sweatshirt-persimmon-red-ss23\"\nresponse = requests.get(URL)\nsoup = BeautifulSoup(response.content, \"html.parser\")\n\n# Get the product title\ntitle = soup.find('h1', class_='product-information_title__Wx52B').get_text()\n\n# Get the product description\ndescription = soup.find('div', class_='accordion_accordion-content__qZ83F', attrs={\"data-locator-id\": \"pdp-accordionContent-DESCRIPTION-read\"}).get_text().replace('\\n', ' ')\n\n# Get the product price\nprice = soup.find('span', class_='product-information_price__6g6xM', attrs={\"data-locator-id\": \"pdp-totalValue-read\"}).get_text()\n\n# Get the available sizes\nsizes_div = soup.find('div', class_='add-to-cart_sizes__qtfGR')\nsizes = [button.get_text() for button in sizes_div.find_all('button', class_='size_size__zRXlq')]\n\n# Uncomment this section to save the scraped data to a CSV file\n# with open('product_data.csv', 'w', newline='') as csvfile:\n#     writer = csv.writer(csvfile)\n#     writer.writerow(['Product Title', 'Product Description', 'Price', 'Available Sizes'])\n#     writer.writerow([title, description, price, ', '.join(sizes)])\n# print(\"Data saved to product_data.csv\")\n\n# Uncomment this section to save the scraped data to a JSON file\ndata = {\n    'Product Title': title,\n    'Product Description': description,\n    'Price': price,\n    'Available Sizes': sizes\n}\n\nwith open('product_data.json', 'w') as jsonfile:\n    json.dump(data, jsonfile)\n\nprint(data)","metadata":{"executionCancelledAt":null,"executionTime":109,"lastExecutedAt":1691520743549,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import requests\nfrom bs4 import BeautifulSoup\nimport json\nimport csv\n\nURL = \"https://us.shop.gymshark.com/products/gymshark-crest-sweatshirt-persimmon-red-ss23\"\nresponse = requests.get(URL)\nsoup = BeautifulSoup(response.content, \"html.parser\")\n\n# Get the product title\ntitle = soup.find('h1', class_='product-information_title__Wx52B').get_text()\n\n# Get the product description\ndescription = soup.find('div', class_='accordion_accordion-content__qZ83F', attrs={\"data-locator-id\": \"pdp-accordionContent-DESCRIPTION-read\"}).get_text().replace('\\n', ' ')\n\n# Get the product price\nprice = soup.find('span', class_='product-information_price__6g6xM', attrs={\"data-locator-id\": \"pdp-totalValue-read\"}).get_text()\n\n# Get the available sizes\nsizes_div = soup.find('div', class_='add-to-cart_sizes__qtfGR')\nsizes = [button.get_text() for button in sizes_div.find_all('button', class_='size_size__zRXlq')]\n\n# Uncomment this section to save the scraped data to a CSV file\n# with open('product_data.csv', 'w', newline='') as csvfile:\n#     writer = csv.writer(csvfile)\n#     writer.writerow(['Product Title', 'Product Description', 'Price', 'Available Sizes'])\n#     writer.writerow([title, description, price, ', '.join(sizes)])\n# print(\"Data saved to product_data.csv\")\n\n# Uncomment this section to save the scraped data to a JSON file\ndata = {\n    'Product Title': title,\n    'Product Description': description,\n    'Price': price,\n    'Available Sizes': sizes\n}\n\nwith open('product_data.json', 'w') as jsonfile:\n    json.dump(data, jsonfile)\n\nprint(data)\n","outputsMetadata":{"0":{"height":97,"type":"stream"}}},"cell_type":"code","id":"aa96a921-52ca-4080-be79-cf63dca3532b","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"{'Product Title': 'Crest Sweatshirt Persimmon Red', 'Product Description': 'REST DAY THE CREST WAY Consistently comfortable and casually stylish, you can wear Crest anywhere and pair it with anything.  • Durable embroidered logo that’ll last through every wear• Soft, brushed back fabric inside for full comfort SIZE & FIT• Slim fit• Model is 6\\'0\" and wears size M MATERIALS & CARE• 80% Cotton, 20% PolyesterSKU:\\xa0A2A1V-RBMB', 'Price': '$36', 'Available Sizes': ['xs', 's', 'm', 'l', 'xl', 'xxl', '3xl']}\n"}]},{"source":"## Selenium Script","metadata":{},"cell_type":"markdown","id":"c055f2e2-2008-4e87-be56-0e224596f416"},{"source":"from selenium import webdriver\nimport json\n\nURL = \"https://us.shop.gymshark.com/products/gymshark-crest-sweatshirt-persimmon-red-ss23\"\n\n### Create a new instance of the browser driver (e.g., Chrome)\ndriver = webdriver.Chrome()\n\n### Navigate to the page\ndriver.get(URL)\n\n### Allow the page to fully load (you may need to adjust the waiting time)\ndriver.implicitly_wait(10)\n\n### Execute JavaScript to get the dataLayer object\ninventory_data = driver.execute_script(\"return window.dataLayer;\")\n\n### Extract the relevant inventory information\nproducts = inventory_data[0]['ecommerce']['detail']['products']\nfor product in products:\n    print(\"Product Name:\", product['name'])\n    for variant in product['variant']:\n        print(f\"Size: {variant['size']}, Inventory Quantity: {variant['inventoryQuantity']}\")\n\n### Close the browser window\ndriver.quit()","metadata":{},"cell_type":"markdown","id":"f8cb97d7-7806-4bab-82e5-4276f3a7bdae"},{"source":"## Conclusion  \nAt the end of this case study, I made a functional web scraping tool that can extract information from the Gymshark Crest Sweatshirt product page in under **15 minutes** using ChatGPT 3.5 Turbo and BeautifulSoup. However, there is more data to be scraped that will require a different method of Selenium.","metadata":{},"cell_type":"markdown","id":"25786d25-f1fc-4bc8-b19b-9022088899b5"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}